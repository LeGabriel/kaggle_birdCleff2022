{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# IMPORT PACKAGES","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import model_from_config\nimport itertools \n\nimport json\nimport random\nrandom.seed(1)\nfrom collections import Counter\n\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm import tqdm\nimport pickle\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle","metadata":{"execution":{"iopub.status.busy":"2022-04-11T17:22:44.687267Z","iopub.execute_input":"2022-04-11T17:22:44.688058Z","iopub.status.idle":"2022-04-11T17:22:44.694965Z","shell.execute_reply.started":"2022-04-11T17:22:44.688014Z","shell.execute_reply":"2022-04-11T17:22:44.693823Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# OPEN FILES","metadata":{}},{"cell_type":"code","source":"def load_data(data_path):\n    with open(data_path, 'rb') as handle:\n        m, mf, ml = pickle.load(handle)\n        \n    #index_puaioh = [i for i in range(len(m)) if ml[i] == 'puaioh']\n    \n    #for idx in index_puaioh:\n     #   m.append(m[idx])\n     #   mf.append(mf[idx])\n     #   ml.append(ml[idx])\n        \n    temp = list(zip(m, mf, ml))\n    random.Random(1).shuffle(temp)\n    res1, res2, res3 = zip(*temp)\n    res1, res2, res3 = list(res1), list(res2), list(res3)\n    \n    res1b, res2b, res3b = [], [], []\n    train_size = 100\n    \n    for bird in tqdm(list(set(res3))):\n        l1 = [] #mels\n        l2 = [] #mels filename\n        l3 = [] #mels label\n        \n        for i, lab in enumerate(res3):\n            if lab == bird:\n                l1.append(res1[i])\n                l2.append(res2[i])\n                l3.append(res3[i])\n        \n        if len(l3) > train_size:\n            l1, _, l2, _, l3, _ = train_test_split(l1, l2, l3, train_size=train_size)\n        \n        res1b += l1\n        res2b += l2\n        res3b += l3\n        \n    \n    print(Counter(res3b))\n    \n    return res1b, res2b, res3b","metadata":{"execution":{"iopub.status.busy":"2022-04-11T17:22:44.791605Z","iopub.execute_input":"2022-04-11T17:22:44.792303Z","iopub.status.idle":"2022-04-11T17:22:44.803732Z","shell.execute_reply.started":"2022-04-11T17:22:44.792244Z","shell.execute_reply":"2022-04-11T17:22:44.802839Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# LOAD FEATURE MODEL","metadata":{}},{"cell_type":"code","source":"def load_feature_model():\n    model_path = '../input/dataset-private'\n\n    model = model_from_config(json.load(open(model_path + '/cmi_mbam01.json', 'r')))\n    model.load_weights(model_path + '/cmi_mbam01.h5')\n\n    feature_layers = [layer.output for layer in model.layers[:-4]]\n    feature_model = tf.keras.Model(inputs=[model.input], outputs=feature_layers)\n    \n    return feature_model","metadata":{"execution":{"iopub.status.busy":"2022-04-11T17:22:44.915241Z","iopub.execute_input":"2022-04-11T17:22:44.915863Z","iopub.status.idle":"2022-04-11T17:22:44.921545Z","shell.execute_reply.started":"2022-04-11T17:22:44.915824Z","shell.execute_reply":"2022-04-11T17:22:44.920361Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# GET FEATURES","metadata":{}},{"cell_type":"code","source":"def get_features(data, feature_model):\n\n    X_all = np.array(data)\n    scale = 33.15998\n\n    X_train_all = X_all[:,:40,:] / scale\n\n    batch_all = X_train_all.reshape(X_train_all.shape[0],\n                                         X_train_all.shape[1],\n                                         X_train_all.shape[2],\n                                         1)\n    \n    \n    embeddings_all = []\n\n    for idx in tqdm(range(len(batch_all)//64+1)):\n        embeddings_all += list(feature_model(batch_all[idx*64:(idx+1)*64])[-1].numpy())\n\n    embeddings_all = np.array(embeddings_all)\n\n    return embeddings_all","metadata":{"execution":{"iopub.status.busy":"2022-04-11T17:22:44.990619Z","iopub.execute_input":"2022-04-11T17:22:44.991206Z","iopub.status.idle":"2022-04-11T17:22:44.998158Z","shell.execute_reply.started":"2022-04-11T17:22:44.991171Z","shell.execute_reply":"2022-04-11T17:22:44.997089Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# GET CLASSIFIER PYTORCH","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom sklearn.metrics import classification_report\n\nclass ClassifierNetwork(nn.Module):\n    def __init__(self, input_size, hidden_size, num_classes):\n        super(ClassifierNetwork, self).__init__()\n\n        self.fc1 = nn.Linear(input_size, hidden_size)\n        self.tanh = nn.Tanh()\n        self.fc2 = nn.Linear(hidden_size, num_classes)\n\n\n    def forward(self, x):\n        out = self.fc1(x)\n        out = self.tanh(out)\n        out = self.fc2(out)\n        return out\n    \n    \n    \ndef train_model(model, features, labels, criterion, optimizer, num_epochs=50, use_tqdm=False):\n    \n    # Train the model\n    \n    x = torch.tensor(features, dtype=torch.float32, device=device)\n    y = torch.tensor(labels, dtype=torch.long, device=device)\n    \n    if use_tqdm:\n        for epoch in tqdm(range(num_epochs)):\n\n            outputs = model(x)\n            loss = criterion(outputs, y)\n\n            c = torch.tensor(gamma, device=device)\n            l2_reg = torch.tensor(0., device=device)\n\n            for name, param in model.named_parameters():\n                if 'weight' in name:\n                    l2_reg += torch.norm(param)\n\n            loss += c * l2_reg\n\n            # Backward and optimize\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n    else:\n        for epoch in range(num_epochs):\n\n            outputs = model(x)\n            loss = criterion(outputs, y)\n\n            c = torch.tensor(gamma, device=device)\n            l2_reg = torch.tensor(0., device=device)\n\n            for name, param in model.named_parameters():\n                if 'weight' in name:\n                    l2_reg += torch.norm(param)\n\n            loss += c * l2_reg\n\n            # Backward and optimize\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        \n        \ndef test_model(model, features, labels):\n    x = torch.tensor(features, dtype=torch.float32, device=device)\n    y = torch.tensor(labels, dtype=torch.long, device=device)\n    with torch.no_grad():\n        correct = 0\n        total = 0\n        outputs = model(x)\n        _, predicted = torch.max(outputs.data, 1)\n        total += y.size(0)\n        correct += (predicted==y).sum().item()\n    \n    return 100 * correct / total, predicted","metadata":{"execution":{"iopub.status.busy":"2022-04-11T17:22:45.059265Z","iopub.execute_input":"2022-04-11T17:22:45.060127Z","iopub.status.idle":"2022-04-11T17:22:45.077986Z","shell.execute_reply.started":"2022-04-11T17:22:45.060077Z","shell.execute_reply":"2022-04-11T17:22:45.077071Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def get_all_embeddings(data_path):\n\n    mels, mels_fname, mels_label = load_data(data_path)\n    feature_model = load_feature_model()\n    embeddings_all = get_features(mels, feature_model)\n\n    return embeddings_all, mels, mels_fname, mels_label","metadata":{"execution":{"iopub.status.busy":"2022-04-11T17:22:45.122723Z","iopub.execute_input":"2022-04-11T17:22:45.124476Z","iopub.status.idle":"2022-04-11T17:22:45.130186Z","shell.execute_reply.started":"2022-04-11T17:22:45.124425Z","shell.execute_reply":"2022-04-11T17:22:45.129355Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def get_proper_split(embeddings_all, mels, mels_fname, mels_label, test_size, random_seed, keep_amount=1e6):\n    \n    dict_label = {l:i for i, l in enumerate(sorted(set(mels_label)))}\n    mels_label_new = [dict_label[m] for m in mels_label]\n    \n    random.seed(1)\n    \n    if keep_amount != 1e6:\n        \n        print('changement')\n        \n        idx_all = []\n        mels_label_new_F = []\n        \n        for b in dict_label.keys():\n            total = min(keep_amount, mels_label_new.count(dict_label[b]))\n            idx_b = [i for i in range(len(mels)) if mels_label_new[i] == dict_label[b]][:total]\n            idx_all += idx_b\n            \n        idx_all = sorted(idx_all)\n        \n        for i in idx_all:\n            mels_label_new_F.append(mels_label_new[i])\n        \n    else:\n        idx_all = [i for i in range(len(mels_fname))]\n        mels_label_new_F = mels_label_new\n    \n    print(Counter(mels_label_new_F))\n    \n    train_idx, test_idx = train_test_split(idx_all, test_size=test_size, random_state=random_seed, shuffle=True, stratify=mels_label_new_F)\n    \n    X_train = np.array([embeddings_all[idx] for idx in train_idx])\n    y_train = np.array([mels_label_new[idx] for idx in train_idx])\n    \n    X_test = np.array([embeddings_all[idx] for idx in test_idx])\n    y_test = np.array([mels_label_new[idx] for idx in test_idx])\n    \n    \n    return X_train, y_train, X_test, y_test, train_idx, test_idx, dict_label, mels_label_new\n\n\ndata_path = '../input/pretrained-create-data-pytorch/ALL_DATA.pickle'\n\ntest_size = 0.5\nrandom_seed = 101  \nqte_keep = 1e6\n\nembeddings_all, mels, mels_fname, mels_label = get_all_embeddings(data_path=data_path)                          \nX_train, y_train, X_test, y_test, index_train, index_test, dict_label, mels_label_new = get_proper_split(embeddings_all,  mels, mels_fname, mels_label, test_size, random_seed, keep_amount=qte_keep)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T17:22:45.187984Z","iopub.execute_input":"2022-04-11T17:22:45.188450Z","iopub.status.idle":"2022-04-11T17:23:13.605953Z","shell.execute_reply.started":"2022-04-11T17:22:45.188418Z","shell.execute_reply":"2022-04-11T17:23:13.604977Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"100%|██████████| 22/22 [00:00<00:00, 221.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Counter({'omao': 100, 'apapan': 100, 'akiapo': 100, 'iiwi': 100, 'hawama': 100, 'jabwar': 100, 'houfin': 100, 'hawhaw': 100, 'elepai': 100, 'aniani': 100, 'maupar': 100, 'zVIDE': 100, 'yefcan': 100, 'warwhe1': 100, 'hawcre': 100, 'hawgoo': 100, 'skylar': 100, 'barpet': 100, 'crehon': 57, 'ercfra': 30, 'hawpet1': 24, 'puaioh': 9})\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 31/31 [00:00<00:00, 86.32it/s]","output_type":"stream"},{"name":"stdout","text":"Counter({16: 100, 2: 100, 0: 100, 13: 100, 7: 100, 14: 100, 12: 100, 10: 100, 5: 100, 1: 100, 15: 100, 21: 100, 20: 100, 19: 100, 8: 100, 9: 100, 18: 100, 3: 100, 4: 57, 6: 30, 11: 24, 17: 9})\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"gamma = 0.5\nlr = 0.01\nnum_epochs = 50\nhl = 1024\n\ngammas = [-0.1, 0] #Positive Gamma is shit\nlrs = [1, 0.1, 0.01, 0.001]\nnum_epochs_s = [10, 30, 50, 100]\nhidden_layers = [64, 128, 256, 512]\ndevice = 'cuda:0'\n\na = [gammas, lrs, num_epochs_s, hidden_layers]\ngrid = list(itertools.product(*a))\nprint(len(grid))\naccuracies = []\n\n\n#RIGHT VALUES :\n\nif True:\n    gammas = [0] #Positive Gamma is shit\n    lrs = [0.01]\n    num_epochs_s = [50]\n    hidden_layers = [64]\n    device = 'cuda:0'\n    a = [gammas, lrs, num_epochs_s, hidden_layers]\n    grid = list(itertools.product(*a))\n\n\nfor gamma, lr, num_epochs, hl in tqdm(grid):\n    \n    \n    model = ClassifierNetwork(512, hl, 22).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    train_model(model, X_train, y_train, criterion, optimizer, num_epochs)\n    \n    accuracy_test, outputs = test_model(model, X_test, y_test)\n    accuracies.append(round(accuracy_test, 2))\n    \n    model_all = ClassifierNetwork(512, hl, 22).to(device)\n    criterion_all = nn.CrossEntropyLoss()\n    optimizer_all = torch.optim.Adam(model.parameters(), lr=lr)\n    train_model(model_all, embeddings_all, mels_label_new, criterion_all, optimizer_all, num_epochs)\n    #_, outputs_all = test_model(model_all, X_test, y_test)\n    \n    \ndf_summary = pd.DataFrame(grid, columns=['Gamma', 'Learning Rate', 'Num Epochs', 'Hidden Layers'])\ndf_summary['Accuracy'] = accuracies","metadata":{"execution":{"iopub.status.busy":"2022-04-11T17:24:57.469595Z","iopub.execute_input":"2022-04-11T17:24:57.470475Z","iopub.status.idle":"2022-04-11T17:24:57.650404Z","shell.execute_reply.started":"2022-04-11T17:24:57.470430Z","shell.execute_reply":"2022-04-11T17:24:57.649609Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"128\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00,  6.27it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"df_summary.sort_values('Accuracy', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T17:24:58.692246Z","iopub.execute_input":"2022-04-11T17:24:58.693297Z","iopub.status.idle":"2022-04-11T17:24:58.706605Z","shell.execute_reply.started":"2022-04-11T17:24:58.693235Z","shell.execute_reply":"2022-04-11T17:24:58.705368Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"   Gamma  Learning Rate  Num Epochs  Hidden Layers  Accuracy\n0      0           0.01          50             64     41.88","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Gamma</th>\n      <th>Learning Rate</th>\n      <th>Num Epochs</th>\n      <th>Hidden Layers</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.01</td>\n      <td>50</td>\n      <td>64</td>\n      <td>41.88</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"classification = classification_report(y_test, outputs.cpu().numpy(), target_names=dict_label)\nprint(classification)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T17:25:00.379005Z","iopub.execute_input":"2022-04-11T17:25:00.379431Z","iopub.status.idle":"2022-04-11T17:25:00.398803Z","shell.execute_reply.started":"2022-04-11T17:25:00.379390Z","shell.execute_reply":"2022-04-11T17:25:00.397987Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n      akiapo       0.30      0.28      0.29        50\n      aniani       0.45      0.54      0.49        50\n      apapan       0.10      0.10      0.10        50\n      barpet       0.85      0.80      0.82        50\n      crehon       0.38      0.39      0.39        28\n      elepai       0.22      0.24      0.23        50\n      ercfra       0.43      0.40      0.41        15\n      hawama       0.37      0.36      0.36        50\n      hawcre       0.31      0.32      0.31        50\n      hawgoo       0.70      0.56      0.62        50\n      hawhaw       0.84      0.94      0.89        50\n     hawpet1       0.56      0.42      0.48        12\n      houfin       0.38      0.34      0.36        50\n        iiwi       0.33      0.30      0.31        50\n      jabwar       0.40      0.38      0.39        50\n      maupar       0.34      0.42      0.38        50\n        omao       0.29      0.32      0.30        50\n      puaioh       0.00      0.00      0.00         5\n      skylar       0.72      0.62      0.67        50\n     warwhe1       0.33      0.40      0.36        50\n      yefcan       0.28      0.20      0.23        50\n       zVIDE       0.41      0.48      0.44        50\n\n    accuracy                           0.42       960\n   macro avg       0.41      0.40      0.40       960\nweighted avg       0.42      0.42      0.42       960\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# SAVE DICT and MODEL","metadata":{}},{"cell_type":"code","source":"with open(\"dico_birds.json\", \"w\") as fp:\n    json.dump(dict_label, fp, indent = 4)\n\nPATH = 'model_pytorch.pt'\nmodel_scripted = torch.jit.script(model.cpu()) # Export to TorchScript\nmodel_scripted.save(PATH) # Save\n\nPATH_ALL = 'model_pytorch_all.pt'\nmodel_scripted_all = torch.jit.script(model_all.cpu()) # Export to TorchScript\nmodel_scripted_all.save(PATH_ALL) # Save","metadata":{"execution":{"iopub.status.busy":"2022-04-11T17:25:02.278174Z","iopub.execute_input":"2022-04-11T17:25:02.278982Z","iopub.status.idle":"2022-04-11T17:25:02.317779Z","shell.execute_reply.started":"2022-04-11T17:25:02.278938Z","shell.execute_reply":"2022-04-11T17:25:02.317008Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# TRY RELOAD","metadata":{}},{"cell_type":"code","source":"model_reloaded = torch.jit.load(PATH)\nprint(model_reloaded)\n\nx_load = torch.tensor(X_test, dtype=torch.float32, device='cpu')\noutputs_loaded = model_reloaded(x_load)\n_, predicted_loaded = torch.max(outputs_loaded.data, 1)\n\nprint(classification_report(y_test, predicted_loaded.numpy(), target_names=dict_label))","metadata":{"execution":{"iopub.status.busy":"2022-04-11T17:25:03.590187Z","iopub.execute_input":"2022-04-11T17:25:03.591023Z","iopub.status.idle":"2022-04-11T17:25:03.616775Z","shell.execute_reply.started":"2022-04-11T17:25:03.590977Z","shell.execute_reply":"2022-04-11T17:25:03.615974Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"RecursiveScriptModule(\n  original_name=ClassifierNetwork\n  (fc1): RecursiveScriptModule(original_name=Linear)\n  (tanh): RecursiveScriptModule(original_name=Tanh)\n  (fc2): RecursiveScriptModule(original_name=Linear)\n)\n              precision    recall  f1-score   support\n\n      akiapo       0.30      0.28      0.29        50\n      aniani       0.45      0.54      0.49        50\n      apapan       0.10      0.10      0.10        50\n      barpet       0.85      0.80      0.82        50\n      crehon       0.38      0.39      0.39        28\n      elepai       0.22      0.24      0.23        50\n      ercfra       0.43      0.40      0.41        15\n      hawama       0.37      0.36      0.36        50\n      hawcre       0.31      0.32      0.31        50\n      hawgoo       0.70      0.56      0.62        50\n      hawhaw       0.84      0.94      0.89        50\n     hawpet1       0.56      0.42      0.48        12\n      houfin       0.38      0.34      0.36        50\n        iiwi       0.33      0.30      0.31        50\n      jabwar       0.40      0.38      0.39        50\n      maupar       0.34      0.42      0.38        50\n        omao       0.29      0.32      0.30        50\n      puaioh       0.00      0.00      0.00         5\n      skylar       0.72      0.62      0.67        50\n     warwhe1       0.33      0.40      0.36        50\n      yefcan       0.28      0.20      0.23        50\n       zVIDE       0.41      0.48      0.44        50\n\n    accuracy                           0.42       960\n   macro avg       0.41      0.40      0.40       960\nweighted avg       0.42      0.42      0.42       960\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}